{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "8afd8226",
      "metadata": {
        "id": "8afd8226"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tifffile import imread\n",
        "import cv2\n",
        "import skimage.io as sio\n",
        "\n",
        "import albumentations as A\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.detection import MaskRCNN, FasterRCNN_ResNet50_FPN_Weights, MaskRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from torchvision.ops import box_convert\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "\n",
        "import pathlib\n",
        "import json\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools import mask as coco_mask\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "5tzWQPzcCgKR",
      "metadata": {
        "id": "5tzWQPzcCgKR"
      },
      "outputs": [],
      "source": [
        "# !gdown https://drive.google.com/file/d/1B0qWNzQZQmfQP7x7o4FDdgb9GvPDoFzI/view --fuzzy\n",
        "# !mkdir ../dataset\n",
        "# !tar -xzf hw3-data-release.tar.gz\n",
        "# !mv test_release/ ../dataset\n",
        "# !mv train/ ../dataset/\n",
        "# !mv test_image_name_to_ids.json ../dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "2ce4b413",
      "metadata": {
        "id": "2ce4b413"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import skimage.io as sio\n",
        "from pycocotools import mask as mask_utils\n",
        "\n",
        "\n",
        "def decode_maskobj(mask_obj):\n",
        "    return mask_utils.decode(mask_obj)\n",
        "\n",
        "\n",
        "def encode_mask(binary_mask):\n",
        "    arr = np.asfortranarray(binary_mask).astype(np.uint8)\n",
        "    rle = mask_utils.encode(arr)\n",
        "    rle['counts'] = rle['counts'].decode('utf-8')\n",
        "    return rle\n",
        "\n",
        "\n",
        "def read_maskfile(filepath):\n",
        "    mask_array = sio.imread(filepath)\n",
        "    return mask_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "8479fbf0",
      "metadata": {
        "id": "8479fbf0"
      },
      "outputs": [],
      "source": [
        "class MedicalDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, data_type='Train'):\n",
        "        self.root = root_dir\n",
        "        self.transform = transform\n",
        "        self.data_type = data_type\n",
        "        if self.data_type not in ['Train', 'Valid', 'Test']:\n",
        "            raise ValueError('Data type should be in [Train, Valid, Test]')\n",
        "        self.samples = self._load_samples()\n",
        "\n",
        "        self.train_coco_path = os.path.join(pathlib.Path(root_dir).parent, 'train_coco.json')\n",
        "        self.val_coco_path = os.path.join(pathlib.Path(root_dir).parent, 'val_coco.json')\n",
        "        if not os.path.exists(self.train_coco_path) or not os.path.exists(self.val_coco_path):\n",
        "            # self.generate_coco(self.train_coco_path)\n",
        "            self.generate_coco_split(self.train_coco_path, self.val_coco_path, split_ratio=0.8)\n",
        "        self.train_coco = COCO(self.train_coco_path)\n",
        "        self.val_coco = COCO(self.val_coco_path)\n",
        "        self.num_classes = len(self.train_coco.loadCats(self.train_coco.getCatIds()))\n",
        "\n",
        "    def _load_samples(self):\n",
        "        samples = []\n",
        "        for img_dir in os.listdir(self.root):\n",
        "            tmp_dir = os.path.join(self.root, img_dir)\n",
        "\n",
        "            if self.data_type == 'Train' or self.data_type == 'Valid':\n",
        "                img_path = os.path.join(tmp_dir, 'image.tif')\n",
        "\n",
        "                mask_paths = [\n",
        "                    entry.name for entry in pathlib.Path(tmp_dir).iterdir()\n",
        "                    if entry.name.startswith(\"class\") and entry.is_file()\n",
        "                ]\n",
        "\n",
        "                samples.append({'image': img_path, 'masks': mask_paths})\n",
        "            elif self.data_type == 'Test':\n",
        "                test_img_json_path = os.path.join(pathlib.Path(self.root).parent, 'test_image_name_to_ids.json')\n",
        "                with open(test_img_json_path, 'r') as f:\n",
        "                    samples = json.load(f)\n",
        "\n",
        "            else:\n",
        "                raise ValueError('Wrong data type')\n",
        "\n",
        "                # for idx in range(len(samples)):\n",
        "                #     samples[idx]['file_name'] = os.path.join(self.root, samples[idx]['file_name'])\n",
        "        return samples\n",
        "\n",
        "    def mask_to_polygons(self, mask, epsilon=1.0):\n",
        "        contours,_ = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "        polygons = []\n",
        "        for contour in contours:\n",
        "            if len(contour) > 2:\n",
        "                poly = contour.reshape(-1).tolist()\n",
        "                if len(poly) > 4: #Ensures valid polygon\n",
        "                    polygons.append(poly)\n",
        "        return polygons\n",
        "\n",
        "    def generate_coco(self, output_dir, train=True):\n",
        "        annotations = []\n",
        "        images = []\n",
        "        categories = []\n",
        "        all_labels = []\n",
        "        ann_id = 0\n",
        "\n",
        "        for img_id, sample in enumerate(self.samples):\n",
        "            print(f'({img_id}/{len(self.samples)})')\n",
        "            img_path, mask_paths = sample['image'], sample['masks']\n",
        "            img = cv2.imread(img_path)\n",
        "            masks = [cv2.imread(os.path.join(pathlib.Path(img_path).parent, mask_path), cv2.IMREAD_UNCHANGED) for mask_path in mask_paths]\n",
        "\n",
        "            images.append({\n",
        "                \"id\": img_id,\n",
        "                \"file_name\": img_path,\n",
        "                \"height\": img.shape[0],\n",
        "                \"width\": img.shape[1]\n",
        "            })\n",
        "\n",
        "            for mask in masks:\n",
        "                unique_values = np.unique(mask)\n",
        "                all_labels.append(unique_values)\n",
        "                for value in unique_values:\n",
        "                    if value == 0:  # Ignore background\n",
        "                        continue\n",
        "\n",
        "                    object_mask = (mask == value).astype(np.uint8) * 255\n",
        "                    polygons = self.mask_to_polygons(object_mask)\n",
        "\n",
        "                    for poly in polygons:\n",
        "                        ann_id += 1\n",
        "                        annotations.append({\n",
        "                            \"id\": ann_id,\n",
        "                            \"image_id\": img_id,\n",
        "                            \"category_id\": 1,  # Only one category: Nuclei\n",
        "                            \"segmentation\": [poly],\n",
        "                            \"area\": cv2.contourArea(np.array(poly).reshape(-1, 2)),\n",
        "                            \"bbox\": list(cv2.boundingRect(np.array(poly).reshape(-1, 2))),\n",
        "                            \"iscrowd\": 0\n",
        "                        })\n",
        "\n",
        "        all_labels = np.unique(np.concatenate(all_labels).tolist())\n",
        "\n",
        "        for idx, label in enumerate(all_labels):\n",
        "            categories.append({\"id\": idx+1, \"name\": int(label)})\n",
        "\n",
        "        coco_input = {\n",
        "            \"images\": images,\n",
        "            \"annotations\": annotations,\n",
        "            \"categories\": categories\n",
        "        }\n",
        "\n",
        "        print(f'Saving train coco json')\n",
        "\n",
        "        with open(output_dir, 'w') as f:\n",
        "            json.dump(coco_input, f)\n",
        "\n",
        "    def generate_coco_split(self, train_coco_path, val_coco_path, split_ratio=0.2):\n",
        "        train_data = {\"images\": [], \"annotations\": [], \"categories\": []}\n",
        "        val_data = {\"images\": [], \"annotations\": [], \"categories\": []}\n",
        "        all_labels = []\n",
        "        ann_id = 0\n",
        "        train_ann = 0\n",
        "        val_ann = 0\n",
        "\n",
        "        # 隨機分離樣本索引\n",
        "        indices = list(range(len(self.samples)))\n",
        "        import random\n",
        "        seed = 123\n",
        "        random.Random(seed).shuffle(indices)\n",
        "        split_point = int(len(indices) * split_ratio)\n",
        "        train_indices = indices[:split_point]\n",
        "        val_indices = indices[split_point:]\n",
        "\n",
        "        # 類別統一管理 (避免訓練/驗證類別不一致)\n",
        "        global_categories = {}\n",
        "\n",
        "        for dataset_type, indices in [(\"train\", train_indices), (\"val\", val_indices)]:\n",
        "            target_data = train_data if dataset_type == \"train\" else val_data\n",
        "\n",
        "            for idx in indices:\n",
        "                sample = self.samples[idx]\n",
        "                img_path, mask_paths = sample['image'], sample['masks']\n",
        "                img = cv2.imread(img_path)\n",
        "                masks = [cv2.imread(os.path.join(pathlib.Path(img_path).parent, mask_path), cv2.IMREAD_UNCHANGED) for mask_path in mask_paths]\n",
        "\n",
        "                image_entry = {\n",
        "                    \"id\": idx,\n",
        "                    \"file_name\": img_path,\n",
        "                    \"height\": img.shape[0],\n",
        "                    \"width\": img.shape[1]\n",
        "                }\n",
        "                target_data[\"images\"].append(image_entry)\n",
        "\n",
        "                for mask in masks:\n",
        "                    unique_values = np.unique(mask)\n",
        "                    all_labels.append(unique_values)\n",
        "                    for value in unique_values:\n",
        "                        if value == 0:  # Ignore background\n",
        "                            continue\n",
        "\n",
        "                        object_mask = (mask == value).astype(np.uint8) * 255\n",
        "                        polygons = self.mask_to_polygons(object_mask)\n",
        "\n",
        "                        for poly in polygons:\n",
        "                            # ann_id += 1\n",
        "                            if dataset_type == 'train':\n",
        "                                train_ann += 1\n",
        "                                ann_id = train_ann\n",
        "                            else:\n",
        "                                val_ann += 1\n",
        "                                ann_id = val_ann\n",
        "\n",
        "                            target_data[\"annotations\"].append({\n",
        "                                \"id\": ann_id,\n",
        "                                \"image_id\": idx,\n",
        "                                \"category_id\": int(value),  # Only one category: Nuclei\n",
        "                                \"segmentation\": [poly],\n",
        "                                \"area\": cv2.contourArea(np.array(poly).reshape(-1, 2)),\n",
        "                                \"bbox\": list(cv2.boundingRect(np.array(poly).reshape(-1, 2))),\n",
        "                                \"iscrowd\": 0\n",
        "                            })\n",
        "\n",
        "        all_labels = np.unique(np.concatenate(all_labels).tolist())\n",
        "\n",
        "        categories = []\n",
        "        for idx, label in enumerate(all_labels):\n",
        "            categories.append({\"id\": idx+1, \"name\": int(label)})\n",
        "        train_data[\"categories\"] = categories\n",
        "        val_data[\"categories\"] = categories\n",
        "\n",
        "\n",
        "        # coco_input = {\n",
        "        #     \"images\": images,\n",
        "        #     \"annotations\": annotations,\n",
        "        #     \"categories\": categories\n",
        "        # }\n",
        "\n",
        "        print(f'Saving  coco json')\n",
        "\n",
        "        with open(train_coco_path, 'w') as f:\n",
        "            json.dump(train_data, f)\n",
        "        with open(val_coco_path, 'w') as f:\n",
        "            json.dump(val_data, f)\n",
        "\n",
        "\n",
        "    def poly2mask(self, segmentation, img_size):\n",
        "        \"\"\"\n",
        "        多邊形標註轉二值掩碼\n",
        "        :param segmentation: COCO格式的多邊形坐標列表 [[x1,y1,x2,y2,...]]\n",
        "        :param img_size: 目標圖像尺寸 (height, width)\n",
        "        \"\"\"\n",
        "        # 自動檢測標註類型\n",
        "        if isinstance(segmentation, dict):\n",
        "            # 處理RLE格式\n",
        "            return coco_mask.decode(segmentation)\n",
        "        else:\n",
        "            # 處理多邊形格式\n",
        "            rle = coco_mask.frPyObjects(segmentation, img_size[0], img_size[1])\n",
        "            return coco_mask.decode(rle)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.data_type == 'Train' or self.data_type == 'Valid':\n",
        "            coco_file = self.train_coco if self.data_type == 'Train' else self.val_coco\n",
        "            img_id = coco_file.dataset['images'][index]['id']\n",
        "            img_ids = coco_file.getImgIds(imgIds=img_id)\n",
        "            img_info = coco_file.loadImgs(img_ids)\n",
        "            # image = cv2.imread(img_info[0]['file_name']) / 255.0\n",
        "            # print(img_info)\n",
        "            image = Image.open(img_info[0]['file_name']).convert(\"RGB\")\n",
        "            image = self.transform(image) if self.transform is not None else image\n",
        "            img_size = [img_info[0]['height'], img_info[0]['width']]\n",
        "\n",
        "\n",
        "            boxes = []\n",
        "            masks = []\n",
        "            labels = []\n",
        "            ann_ids = coco_file.getAnnIds(imgIds=img_ids)\n",
        "            annotations = coco_file.loadAnns(ann_ids)\n",
        "            for ann in annotations:\n",
        "                boxes.append(ann['bbox'])\n",
        "                tmp_mask = self.poly2mask(ann['segmentation'], img_size).squeeze()\n",
        "                # mask_ = F.interpolate(\n",
        "                #     tmp_mask,\n",
        "                #     size=(224, 224),\n",
        "                #     mode='nearest-exact'  # PyTorch 1.10+ 專用選項\n",
        "                # )\n",
        "                mask_ = cv2.resize(\n",
        "                    tmp_mask,\n",
        "                    (224, 224),\n",
        "                    interpolation=cv2.INTER_NEAREST_EXACT  # 精確最近鄰算法\n",
        "                )\n",
        "                masks.append(mask_)\n",
        "                labels.append(ann[\"category_id\"])\n",
        "\n",
        "            boxes = self.resize_box(boxes, img_size, target_size=[224,224])\n",
        "            boxes = box_convert(torch.tensor(boxes, dtype=torch.float32), in_fmt='xywh', out_fmt='xyxy')\n",
        "            masks = torch.as_tensor(np.array(masks), dtype=torch.bool)\n",
        "\n",
        "            target = {'boxes': torch.as_tensor(boxes, dtype=torch.float32),\n",
        "                      'masks': masks,\n",
        "                      'labels': torch.as_tensor(np.array(labels), dtype=torch.int64)}\n",
        "\n",
        "            return img_id, image, target\n",
        "        else:\n",
        "            raise ValueError('This is test, not yet implement')\n",
        "\n",
        "    def resize_box(self, boxes, orig_size, target_size):\n",
        "        # Eat xywh\n",
        "        scale_w = target_size[1] / orig_size[1]\n",
        "        scale_h = target_size[0] / orig_size[0]\n",
        "\n",
        "        for box in boxes:\n",
        "            box[0] *= scale_w  # x\n",
        "            box[1] *= scale_h  # y\n",
        "            box[2] *= scale_w  # w\n",
        "            box[3] *= scale_h  # h\n",
        "\n",
        "        return boxes\n",
        "\n",
        "    def __len__(self):\n",
        "        coco_file = self.train_coco if self.data_type == 'Train' else self.val_coco\n",
        "        return len(coco_file.dataset['images'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "d0d4d02e",
      "metadata": {
        "id": "d0d4d02e"
      },
      "outputs": [],
      "source": [
        "project_root = '..'\n",
        "train_dir = os.path.join(project_root, 'dataset/train')\n",
        "test_dir = os.path.join(project_root, 'dataset/test_release')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "9a321fc7",
      "metadata": {
        "id": "9a321fc7"
      },
      "outputs": [],
      "source": [
        "# train_coco_path = f'/home/bhg/visual_dl/lab3/dataset'\n",
        "# val_coco_path = f'/home/bhg/visual_dl/lab3/dataset'\n",
        "# train_set = MedicalDataset(root_dir=train_dir, data_type='Train')\n",
        "# val_transform=T.Compose([\n",
        "#     T.ToTensor(),\n",
        "#     T.Resize(size=[224,224], antialias=True),\n",
        "#     # T.CenterCrop(size=224),\n",
        "#     # T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# ])\n",
        "# val_set = MedicalDataset(root_dir=train_dir, data_type='Valid', transform=val_transform)\n",
        "\n",
        "# print(val_set[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "52e557f9",
      "metadata": {
        "id": "52e557f9"
      },
      "outputs": [],
      "source": [
        "# train_transform=T.Compose([\n",
        "#     T.ToTensor(),\n",
        "#     T.Resize(size=[224,224], antialias=True),\n",
        "#     # T.CenterCrop(size=224),\n",
        "#     # T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# ])\n",
        "# train_set = MedicalDataset(root_dir=train_dir, transform=train_transform)\n",
        "# img, target = train_set[1]\n",
        "# print(f\"box: {target['boxes'].shape}\")\n",
        "# print(f\"mask: {target['masks'].shape}\")\n",
        "# print(f\"label: {target['labels'].shape}\")\n",
        "# print(target['boxes'][0])\n",
        "\n",
        "# print(img, img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "0a354976",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "0a354976",
        "outputId": "55840aee-484b-40a9-aabf-6f89b622e918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "122 {'boxes': tensor([[104.8547, 105.2824, 112.7748, 114.3206],\n",
            "        [113.6357, 107.2366, 118.6287, 113.5878],\n",
            "        [ 21.8663,  52.0305,  26.6872,  60.0916],\n",
            "        ...,\n",
            "        [ 93.6633, 115.0534,  96.9347, 119.6947],\n",
            "        [ 79.0284,  24.9160,  81.9554,  31.0229],\n",
            "        [ 81.4389,  34.6870,  84.7102,  41.0382]]), 'masks': tensor([[[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]],\n",
            "\n",
            "        [[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]],\n",
            "\n",
            "        [[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]],\n",
            "\n",
            "        [[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]],\n",
            "\n",
            "        [[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]]]), 'labels': tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
            "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
            "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
            "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
            "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
            "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
            "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
            "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
            "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
            "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
            "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
            "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
            "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
            "        182, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
            "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
            "        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
            "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
            "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
            "        251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
            "        265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
            "        279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292,\n",
            "        293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
            "        307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
            "        321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 330, 331, 332, 333,\n",
            "        334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347,\n",
            "        348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
            "        362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375,\n",
            "        376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
            "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
            "        404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
            "        418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
            "        432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
            "        446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
            "        460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
            "        474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487,\n",
            "        488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501,\n",
            "        502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
            "        516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529,\n",
            "        530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543,\n",
            "        544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557,\n",
            "        558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
            "        572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585,\n",
            "        586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599,\n",
            "        600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613,\n",
            "        614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627,\n",
            "        628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641,\n",
            "        642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655,\n",
            "        656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669,\n",
            "        670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683,\n",
            "        684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697,\n",
            "        698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711,\n",
            "        712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725,\n",
            "        726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739,\n",
            "        740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
            "        754, 755, 756, 757, 758, 759, 760, 761])}\n"
          ]
        }
      ],
      "source": [
        "# train_transform = A.Compose([\n",
        "#     A.HorizontalFlip(p=0.5),\n",
        "#     A.VerticalFlip(p=0.3),\n",
        "#     A.Rotate(limit=15, p=0.4),\n",
        "#     A.CLAHE(p=0.5),\n",
        "#     A.GridDistortion(p=0.2),\n",
        "#     A.RandomBrightnessContrast(p=0.3)\n",
        "# ], additional_targets={'mask': 'mask'})\n",
        "train_transform=T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Resize(size=[224, 224], antialias=True),\n",
        "    # T.CenterCrop(size=224),\n",
        "    # T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = train_transform\n",
        "\n",
        "train_set = MedicalDataset(root_dir=train_dir, transform=train_transform, data_type='Train')\n",
        "val_set = MedicalDataset(root_dir=train_dir, transform=val_transform, data_type='Valid')\n",
        "img_id, img, tar = val_set[0]\n",
        "print(img_id, tar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "93m5-5g8IUGS",
      "metadata": {
        "id": "93m5-5g8IUGS"
      },
      "outputs": [],
      "source": [
        "max_choices = 70\n",
        "\n",
        "def custom_collate(batch):\n",
        "    img_ids = []\n",
        "    images = []\n",
        "    targets = []\n",
        "\n",
        "    # print(batch[0][1])\n",
        "\n",
        "    for img_id, img, target in batch:\n",
        "        img_ids.append(img_id)\n",
        "        images.append(img)\n",
        "        # print(type(target['boxes']))\n",
        "        # keep_idx = torch.randperm(target['boxes'].shape[0])[:max_choices]\n",
        "        n = target['boxes'].shape[0]\n",
        "        targets.append({\n",
        "            'boxes': target['boxes'][torch.randperm(n)[:max_choices]],\n",
        "            'labels': target['labels'][torch.randperm(n)[:max_choices]],\n",
        "            'masks': target['masks'][torch.randperm(n)[:max_choices]]\n",
        "        })\n",
        "\n",
        "    images = torch.stack(images, dim=0)\n",
        "    return img_ids, images, targets\n",
        "\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=False, collate_fn=custom_collate)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=False, collate_fn=custom_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fed2186",
      "metadata": {
        "id": "0fed2186"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, val_loader, val_coco, epoch, device):\n",
        "    # 初始化 COCO 格式儲存器\n",
        "    coco_gt = val_coco  # 需提前加載驗證集註解文件\n",
        "    coco_results = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        bar = tqdm(val_loader, desc='Eval', leave=False)\n",
        "        for img_ids, images, targets in bar:\n",
        "            images = [img.to(device) for img in images]\n",
        "            outputs = model(images)\n",
        "\n",
        "            # 轉換預測結果到 COCO 格式\n",
        "            for i in range(len(outputs)):\n",
        "                image_id = img_ids[i]\n",
        "                output = outputs[i]\n",
        "\n",
        "                # 處理每個實例預測\n",
        "                for j in range(len(output[\"boxes\"])):\n",
        "                    box = output[\"boxes\"][j].cpu().numpy()\n",
        "                    score = output[\"scores\"][j].item()\n",
        "                    label = output[\"labels\"][j].item()\n",
        "                    mask = output[\"masks\"][j][0].cpu().numpy()  # (H,W)\n",
        "\n",
        "                    # 生成 RLE 編碼 (COCO 要求格式)\n",
        "                    rle = encode_mask(mask > 0.5)  # 閾值處理\n",
        "\n",
        "                    coco_results.append({\n",
        "                        \"image_id\": image_id,\n",
        "                        \"category_id\": label,\n",
        "                        \"segmentation\": rle,\n",
        "                        \"bbox\": [box[0], box[1], box[2]-box[0], box[3]-box[1]],  # xywh\n",
        "                        \"score\": score\n",
        "                    })\n",
        "            bar.update()\n",
        "\n",
        "        bar.close()\n",
        "\n",
        "    with open(f'../results/{epoch}_res.json', 'w') as f:\n",
        "        json.dump(coco_results, f)\n",
        "\n",
        "    # 評估計算\n",
        "    coco_dt = coco_gt.loadRes(coco_results)\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, 'segm')\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "\n",
        "    return coco_eval.stats  # 返回 AP 系列指標"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "86b46772",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86b46772",
        "outputId": "997d5fce-b0aa-4e5d-a726-0aec1d70f563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "773\n"
          ]
        }
      ],
      "source": [
        "num_classes=train_set.num_classes\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "04b7d57f",
      "metadata": {
        "id": "04b7d57f"
      },
      "outputs": [],
      "source": [
        "def build_model(num_classes):\n",
        "    from torchvision.models.detection import MaskRCNN_ResNet50_FPN_V2_Weights\n",
        "    from torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT)\n",
        "\n",
        "    # 2. 替換分類器\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)  # 自定義類別數\n",
        "\n",
        "    # 3. 替換掩碼分類器\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
        "        in_features_mask, hidden_layer, num_classes\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "53a6faf2",
      "metadata": {
        "id": "53a6faf2"
      },
      "outputs": [],
      "source": [
        "os.makedirs('../ckpt', exist_ok=True)\n",
        "os.makedirs('../results', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "aa0b176f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "val_coco = COCO('../dataset/val_coco.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e358b9b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d5cfcb14c34e4733b1ddb3a0ee097152",
            "5464f677cf3340ab8e9b177bbbba4376",
            "11d3fa00d6cb442a9bcd3316baea123f",
            "8f8b42531a3246df868f373f2cc74550",
            "5e1a195aaaa84049992485cec3b01212",
            "65c76418d5184cc19ed29dac5d2cfce0",
            "8e01b6df84f146a4b0ea5c3947547cae",
            "58e242678613499c92a91ced71b64868",
            "acc3f8c5fe734d08ba2341324d1754b5",
            "199fbdabdb024f7ca4c33984e7b3ba6e",
            "d88925e11cde4dbeb5a560f56264aabf",
            "8b736ddc9be04172b2453a9bc530dacd",
            "ee0ff36951b243f5932492f79abf7ece",
            "1db32642d7c742cb8637c40040802ef7",
            "6de048732365407f9893b715f4877024",
            "de1dd14648c24eef960feb14f92bf304",
            "0c2ec4d19ae34e12ba32bed5bd9dd871",
            "68c257536a8245538fc6e8b7c7cfe45e",
            "3339de0e3a5e419783f097b8808cc268",
            "1529adc6925d411bbbb4a17beb5d6455",
            "faa156bfbc8e41beb059defa2517b3a9",
            "3c251cc67827437d9ab354dfbe90b996",
            "61acc44cb1e647918b5df112ef5a5dda",
            "3e0fa501f2604e1c90025203e22cec11",
            "18abf7842f51420384dbb718e7e9caf7",
            "9a4d3afa7abe428ea336380bad72dce2",
            "490b0ab7c9984d179af7e3c466ea95ef",
            "6b5a1522d27d4cbdbba76242b21206be",
            "2eabe2d5be504f549db618e51458485a",
            "22cd7d39cc4f496b8acc265c731fc4c6",
            "0616ea571b224d198122ae488d7929a4",
            "bdce13bf4ad141ce9a018efe532ce657",
            "838c6455d0254816b5902fc2ed5d4780"
          ]
        },
        "id": "e358b9b3",
        "outputId": "76e5aa8d-db64-48a7-b353-bab3b69c46ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 42/42 [00:25<00:00,  1.63it/s, loss=8.99]\n",
            "Epochs:   0%|          | 0/2 [00:30<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preparing results...\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[136]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     32\u001b[39m     bar.update()\n\u001b[32m     35\u001b[39m bar.close()\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28meval\u001b[39m = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_coco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28meval\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, val_loader, val_coco, epoch, device)\u001b[39m\n\u001b[32m     40\u001b[39m     json.dump(coco_results, f)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# 評估計算\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m coco_dt = \u001b[43mcoco_gt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloadRes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoco_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m coco_eval = COCOeval(coco_gt, coco_dt, \u001b[33m'\u001b[39m\u001b[33msegm\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     45\u001b[39m coco_eval.evaluate()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test/lib/python3.13/site-packages/pycocotools/coco.py:329\u001b[39m, in \u001b[36mCOCO.loadRes\u001b[39m\u001b[34m(self, resFile)\u001b[39m\n\u001b[32m    326\u001b[39m annsImgIds = [ann[\u001b[33m'\u001b[39m\u001b[33mimage_id\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m anns]\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(annsImgIds) == (\u001b[38;5;28mset\u001b[39m(annsImgIds) & \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m.getImgIds())), \\\n\u001b[32m    328\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mResults do not correspond to current coco set\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcaption\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43manns\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m    330\u001b[39m     imgIds = \u001b[38;5;28mset\u001b[39m([img[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m res.dataset[\u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m]]) & \u001b[38;5;28mset\u001b[39m([ann[\u001b[33m'\u001b[39m\u001b[33mimage_id\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m anns])\n\u001b[32m    331\u001b[39m     res.dataset[\u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m] = [img \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m res.dataset[\u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m img[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m imgIds]\n",
            "\u001b[31mIndexError\u001b[39m: list index out of range"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = build_model(num_classes).to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "num_epochs = 2\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "    model.train()\n",
        "    bar = tqdm(train_loader, desc=f\"Training\")\n",
        "\n",
        "    loss_per_epoch = []\n",
        "    for img_ids, images, targets in bar:\n",
        "        # print(\"1\")\n",
        "        images = [image.to(device) for image in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # print(targets[0]['boxes'].shape)\n",
        "        # print(img_ids)\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        sum_of_loss = sum(loss for loss in loss_dict.values())\n",
        "        loss_per_epoch.append(sum_of_loss.detach().cpu())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        sum_of_loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        bar.set_postfix(loss=np.mean(loss_per_epoch))\n",
        "        bar.update()\n",
        "\n",
        "\n",
        "    bar.close()\n",
        "\n",
        "    # eval = evaluate_model(model, val_loader, val_coco, epoch, device)\n",
        "    # print(eval)\n",
        "    # with open(f'../results/{epoch}.json', 'w') as f:\n",
        "    #     json.dump(eval, f)\n",
        "\n",
        "    torch.save(model.state_dict(), f'../ckpt/{epoch}.pth')\n",
        "\n",
        "torch.save(model.state_dict(), '../ckpt/last.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2813e4ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2813e4ba",
        "outputId": "85501972-6f88-4fb0-db2a-a351b4eadacc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inference:   2%|▏         | 1/42 [00:00<00:29,  1.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:   7%|▋         | 3/42 [00:00<00:10,  3.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  12%|█▏        | 5/42 [00:02<00:22,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  14%|█▍        | 6/42 [00:03<00:18,  1.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  19%|█▉        | 8/42 [00:03<00:15,  2.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  21%|██▏       | 9/42 [00:04<00:13,  2.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  24%|██▍       | 10/42 [00:07<00:40,  1.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  29%|██▊       | 12/42 [00:10<00:39,  1.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  31%|███       | 13/42 [00:11<00:38,  1.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  33%|███▎      | 14/42 [00:12<00:34,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  36%|███▌      | 15/42 [00:14<00:37,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  40%|████      | 17/42 [00:16<00:28,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  43%|████▎     | 18/42 [00:16<00:22,  1.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  45%|████▌     | 19/42 [00:17<00:19,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  48%|████▊     | 20/42 [00:19<00:25,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  50%|█████     | 21/42 [00:21<00:28,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  55%|█████▍    | 23/42 [00:21<00:15,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  57%|█████▋    | 24/42 [00:24<00:23,  1.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  60%|█████▉    | 25/42 [00:24<00:17,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  62%|██████▏   | 26/42 [00:24<00:13,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  64%|██████▍   | 27/42 [00:24<00:09,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  67%|██████▋   | 28/42 [00:25<00:10,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  71%|███████▏  | 30/42 [00:26<00:05,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  74%|███████▍  | 31/42 [00:26<00:05,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  76%|███████▌  | 32/42 [00:26<00:03,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  79%|███████▊  | 33/42 [00:28<00:05,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  81%|████████  | 34/42 [00:28<00:04,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  83%|████████▎ | 35/42 [00:28<00:03,  2.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  86%|████████▌ | 36/42 [00:28<00:02,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  90%|█████████ | 38/42 [00:30<00:02,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  93%|█████████▎| 39/42 [00:31<00:01,  1.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  95%|█████████▌| 40/42 [00:31<00:01,  1.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference:  98%|█████████▊| 41/42 [00:31<00:00,  2.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference: 100%|██████████| 42/42 [00:32<00:00,  2.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference: 43it [00:32,  2.52it/s]                        "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference: 44it [00:33,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference: 45it [00:33,  2.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference: 47it [00:33,  3.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference: 48it [00:34,  3.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference: 49it [00:34,  3.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inference: 51it [00:36,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n",
            "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0'), 'masks': tensor([], device='cuda:0', size=(0, 1, 224, 224))}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rInference: 100%|██████████| 42/42 [00:36<00:00,  1.16it/s]\n"
          ]
        }
      ],
      "source": [
        "ckpt_path = f'../ckpt/last.pth'\n",
        "model = build_model(num_classes).to(device)\n",
        "model.load_state_dict(torch.load(ckpt_path))\n",
        "model.eval()\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision.ops import box_convert\n",
        "\n",
        "bar = tqdm(train_loader, desc=\"Inference\", total=len(train_loader))\n",
        "for img_ids, images, targets in bar:\n",
        "    images = list(image.to(device) for image in images)\n",
        "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(images)\n",
        "\n",
        "    print(predictions)\n",
        "\n",
        "    # for i, prediction in enumerate(predictions):\n",
        "    #     boxes = prediction['boxes'].cpu().numpy()\n",
        "    #     masks = prediction['masks'].cpu().numpy()\n",
        "    #     labels = prediction['labels'].cpu().numpy()\n",
        "\n",
        "    #     # Process the predictions as needed\n",
        "    #     print(f\"Image {i}:\")\n",
        "    #     print(\"Boxes:\", boxes)\n",
        "    #     print(\"Masks:\", masks)\n",
        "    #     print(\"Labels:\", labels)\n",
        "\n",
        "    bar.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7c4e071",
      "metadata": {
        "id": "c7c4e071"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.get_model(\n",
        "        args.model, weights=args.weights, weights_backbone=args.weights_backbone, num_classes=num_classes, **kwargs\n",
        "    )\n",
        "model.roi_heads.box_predictor.cls_score = nn.Linear(in_features=1024, out_features=len(class_names),bias=True)\n",
        "model.roi_heads.box_predictor.bbox_pred = nn.Linear(in_features=1024, out_features=len(class_names)*4,bias=True)\n",
        "model.roi_heads.mask_predictor.mask_fcn_logits = nn.Conv2d(256, len(class_names),kernel_size=(1,1),stride=(1,1))\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe24224b",
      "metadata": {
        "id": "fe24224b"
      },
      "outputs": [],
      "source": [
        "def masks_to_coco(results, image_ids):\n",
        "    coco_results = []\n",
        "    for img_id, output in zip(image_ids, results):\n",
        "        for score, mask, label in zip(output['scores'], output['masks'], output['labels']):\n",
        "            rle = binary_mask_to_rle(mask)\n",
        "            coco_results.append({\n",
        "                \"image_id\": img_id,\n",
        "                \"category_id\": label.item(),\n",
        "                \"segmentation\": rle,\n",
        "                \"score\": score.item()\n",
        "            })\n",
        "    return coco_results\n",
        "\n",
        "def binary_mask_to_rle(mask):\n",
        "    # RLE編碼實現\n",
        "    pixels = mask.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return {'size': list(mask.shape[-2:]), 'counts': runs.tolist()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06683b20",
      "metadata": {
        "id": "06683b20"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "test_loader = DataLoader(test_set, batch_size=2, shuffle=False)\n",
        "\n",
        "results = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        outputs = model(batch.to(device))\n",
        "        results.extend(outputs)\n",
        "\n",
        "# 生成最終提交文件\n",
        "with open('test-results.json', 'w') as f:\n",
        "    json.dump(masks_to_coco(results, test_set.image_ids), f)\n",
        "\n",
        "print(\"Submission file generated!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0616ea571b224d198122ae488d7929a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c2ec4d19ae34e12ba32bed5bd9dd871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d3fa00d6cb442a9bcd3316baea123f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e242678613499c92a91ced71b64868",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acc3f8c5fe734d08ba2341324d1754b5",
            "value": 2
          }
        },
        "1529adc6925d411bbbb4a17beb5d6455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18abf7842f51420384dbb718e7e9caf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22cd7d39cc4f496b8acc265c731fc4c6",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0616ea571b224d198122ae488d7929a4",
            "value": 42
          }
        },
        "199fbdabdb024f7ca4c33984e7b3ba6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db32642d7c742cb8637c40040802ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3339de0e3a5e419783f097b8808cc268",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1529adc6925d411bbbb4a17beb5d6455",
            "value": 42
          }
        },
        "22cd7d39cc4f496b8acc265c731fc4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eabe2d5be504f549db618e51458485a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3339de0e3a5e419783f097b8808cc268": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c251cc67827437d9ab354dfbe90b996": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e0fa501f2604e1c90025203e22cec11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b5a1522d27d4cbdbba76242b21206be",
            "placeholder": "​",
            "style": "IPY_MODEL_2eabe2d5be504f549db618e51458485a",
            "value": "Training: 100%"
          }
        },
        "490b0ab7c9984d179af7e3c466ea95ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5464f677cf3340ab8e9b177bbbba4376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65c76418d5184cc19ed29dac5d2cfce0",
            "placeholder": "​",
            "style": "IPY_MODEL_8e01b6df84f146a4b0ea5c3947547cae",
            "value": "Epochs: 100%"
          }
        },
        "58e242678613499c92a91ced71b64868": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1a195aaaa84049992485cec3b01212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61acc44cb1e647918b5df112ef5a5dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e0fa501f2604e1c90025203e22cec11",
              "IPY_MODEL_18abf7842f51420384dbb718e7e9caf7",
              "IPY_MODEL_9a4d3afa7abe428ea336380bad72dce2"
            ],
            "layout": "IPY_MODEL_490b0ab7c9984d179af7e3c466ea95ef"
          }
        },
        "65c76418d5184cc19ed29dac5d2cfce0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c257536a8245538fc6e8b7c7cfe45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b5a1522d27d4cbdbba76242b21206be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de048732365407f9893b715f4877024": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa156bfbc8e41beb059defa2517b3a9",
            "placeholder": "​",
            "style": "IPY_MODEL_3c251cc67827437d9ab354dfbe90b996",
            "value": " 42/42 [00:48&lt;00:00,  1.30it/s, loss=3.56]"
          }
        },
        "838c6455d0254816b5902fc2ed5d4780": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b736ddc9be04172b2453a9bc530dacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee0ff36951b243f5932492f79abf7ece",
              "IPY_MODEL_1db32642d7c742cb8637c40040802ef7",
              "IPY_MODEL_6de048732365407f9893b715f4877024"
            ],
            "layout": "IPY_MODEL_de1dd14648c24eef960feb14f92bf304"
          }
        },
        "8e01b6df84f146a4b0ea5c3947547cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f8b42531a3246df868f373f2cc74550": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_199fbdabdb024f7ca4c33984e7b3ba6e",
            "placeholder": "​",
            "style": "IPY_MODEL_d88925e11cde4dbeb5a560f56264aabf",
            "value": " 2/2 [01:33&lt;00:00, 46.17s/it]"
          }
        },
        "9a4d3afa7abe428ea336380bad72dce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdce13bf4ad141ce9a018efe532ce657",
            "placeholder": "​",
            "style": "IPY_MODEL_838c6455d0254816b5902fc2ed5d4780",
            "value": " 42/42 [00:43&lt;00:00,  1.03it/s, loss=3.41]"
          }
        },
        "acc3f8c5fe734d08ba2341324d1754b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdce13bf4ad141ce9a018efe532ce657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5cfcb14c34e4733b1ddb3a0ee097152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5464f677cf3340ab8e9b177bbbba4376",
              "IPY_MODEL_11d3fa00d6cb442a9bcd3316baea123f",
              "IPY_MODEL_8f8b42531a3246df868f373f2cc74550"
            ],
            "layout": "IPY_MODEL_5e1a195aaaa84049992485cec3b01212"
          }
        },
        "d88925e11cde4dbeb5a560f56264aabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de1dd14648c24eef960feb14f92bf304": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ee0ff36951b243f5932492f79abf7ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c2ec4d19ae34e12ba32bed5bd9dd871",
            "placeholder": "​",
            "style": "IPY_MODEL_68c257536a8245538fc6e8b7c7cfe45e",
            "value": "Training: 100%"
          }
        },
        "faa156bfbc8e41beb059defa2517b3a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
